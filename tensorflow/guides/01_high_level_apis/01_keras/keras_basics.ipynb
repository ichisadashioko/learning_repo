{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "- Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
    "\n",
    "    - *User friendly*: Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
    "    \n",
    "    - *Modular and composable*: Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
    "    \n",
    "    - *Easy to extend*: Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tf.keras\n",
    "\n",
    "- `tf.keras` is TensorFlow's implementation of the [Keras API specification](https://keras.io/). This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality, such as [eager execution](https://www.tensorflow.org/guide/keras#eager_execution), `tf.data` pipelines, and [Estimators](https://www.tensorflow.org/guide/estimators). `tf.keras` makes TensorFlow easier to use without sacrificing flexibility and performance.\n",
    "\n",
    "- To get started, import `tf.keras` as part of your TensorFlow program setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyyaml # Require to save models in YAML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.keras` can run any Keras-compatiable code, but keep in mind:\n",
    "\n",
    "    - The `tf.keras` version in the latest TensorFlow release might not be the same as the latest `keras` version from PyPI. Check `tf.keras.version`.\n",
    "    \n",
    "    - When [saving a model's weights](https://www.tensorflow.org/guide/keras#weights_only), defaults to the [checkpoint format](https://www.tensorflow.org/guide/checkpoints). Pass `save_format='h5'` to use HDF5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model\n",
    "\n",
    "### Sequential moodel\n",
    "\n",
    "- In Keras, you assemble `layers` to build `models`. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the `tf.keras.Sequential` model.\n",
    "\n",
    "- To build a simple, fully-connected network (i.e. multi-layer perceptron):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 outputs units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the layers\n",
    "\n",
    "- There are many `tf.keras.layers` available with some common constructor parameters:\n",
    "\n",
    "    - `activation`: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
    "    \n",
    "    - `kernel_initializer` and `bias_initializer`: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
    "    \n",
    "    - `kernel_regularizer` and `bias_regularizer`: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied.\n",
    "    \n",
    "- The following instantiates `tf.keras.layers.Dense` layers using constructor arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2261e609550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "\n",
    "### Set up training\n",
    "\n",
    "- After the model is constructed, configure its learning process by calling the `compile` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shioko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Add a densely-connected layer with 64 units to the model:\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    # Add another:\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    # Add a softmax layer with 10 output units:\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.keras.Model.compile` takes three important arguments:\n",
    "    \n",
    "    - `optimizer`: This object specifies the training procedures. Pass it optimizer instances from the `tf.train` module, such as `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`, or `tf.train.GradientDescentOptimizer`.\n",
    "    \n",
    "    - `loss`: The function to minimize during optimization. Common choices include mean square error(`mse`), `categorical_crossentropy`, and `binary_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
    "    \n",
    "    - `metrics`: Used to monitor training. These are string names or callables from the `tf.keras.metrics` module.\n",
    "    \n",
    "- The following shows a few examples of configuring a model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shioko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01), \n",
    "              loss='mse', # mean squared error\n",
    "              metrics=['mae']) # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01), \n",
    "              loss=tf.keras.losses.categorical_crossentropy, \n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input NumPy data\n",
    "\n",
    "- For small datasets, use in-memory NumPy arrays to train and evaluate a model. The model is \"fit\" to the training data using the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shioko\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 885us/sample - loss: 11.5947 - categorical_accuracy: 0.0920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 11.5469 - categorical_accuracy: 0.1050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 11.5367 - categorical_accuracy: 0.1010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 11.5275 - categorical_accuracy: 0.1080\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 11.5289 - categorical_accuracy: 0.1090\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 11.5270 - categorical_accuracy: 0.0910\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 11.5241 - categorical_accuracy: 0.0970\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 11.5229 - categorical_accuracy: 0.1210\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 11.5189 - categorical_accuracy: 0.1070\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 11.5146 - categorical_accuracy: 0.1180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2261e609208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.keras.Model.fit` takes three important arguments:\n",
    "\n",
    "    - `epochs`: Training is structured into `epochs`. An epoch is one iteration over the entire input data (this is done in smaller batches).\n",
    "    - `batch_size`: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specfies the size of each batch. Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
    "    - `validation_data`: When prototyping a model, you want to easily monitor its performance on some validation data. Passing this argument - a tuple of inputs and labels - allows the model to display the loss and metrics in inference mode for the passed data, at the end of each epoch.\n",
    "    \n",
    "- Here's an example using `validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 164us/sample - loss: 11.5421 - categorical_accuracy: 0.1000 - val_loss: 11.5382 - val_categorical_accuracy: 0.0900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 11.5382 - categorical_accuracy: 0.1050 - val_loss: 11.5386 - val_categorical_accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 11.5371 - categorical_accuracy: 0.0940 - val_loss: 11.5456 - val_categorical_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 11.5377 - categorical_accuracy: 0.1270 - val_loss: 11.5471 - val_categorical_accuracy: 0.0800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 11.5352 - categorical_accuracy: 0.1200 - val_loss: 11.5379 - val_categorical_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 11.5352 - categorical_accuracy: 0.1340 - val_loss: 11.5595 - val_categorical_accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 11.5319 - categorical_accuracy: 0.1360 - val_loss: 11.5457 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.5315 - categorical_accuracy: 0.125 - 0s 125us/sample - loss: 11.5303 - categorical_accuracy: 0.1250 - val_loss: 11.5438 - val_categorical_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 11.5247 - categorical_accuracy: 0.1210 - val_loss: 11.5510 - val_categorical_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 11.5255 - categorical_accuracy: 0.1350 - val_loss: 11.5467 - val_categorical_accuracy: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22645296128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32, \n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input tf.data datasets\n",
    "\n",
    "- Use the [Datasets API](https://www.tensorflow.org/guide/datasets) to scale large datasets or multi-device training. Pass a `tf.data.Dataset` instance to the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5148 - categorical_accuracy: 0.1385\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5142 - categorical_accuracy: 0.1400\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.5258 - categorical_accuracy: 0.1464\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5150 - categorical_accuracy: 0.1314\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4936 - categorical_accuracy: 0.1453\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4662 - categorical_accuracy: 0.1528\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5040 - categorical_accuracy: 0.1389\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4637 - categorical_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5114 - categorical_accuracy: 0.1699\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5077 - categorical_accuracy: 0.1560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x226452ab630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `step_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, the `fit` method uses the `steps_per_epoch` argument - this is the number of training steps the model runs before it moves to the next epochs, Since the `Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
    "\n",
    "- Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 11.4793 - categorical_accuracy: 0.1792 - val_loss: 11.6016 - val_categorical_accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4669 - categorical_accuracy: 0.1720 - val_loss: 11.5447 - val_categorical_accuracy: 0.1176\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4820 - categorical_accuracy: 0.1645 - val_loss: 11.6192 - val_categorical_accuracy: 0.0294\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4687 - categorical_accuracy: 0.1677 - val_loss: 11.4595 - val_categorical_accuracy: 0.0882\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4547 - categorical_accuracy: 0.1891 - val_loss: 11.6068 - val_categorical_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4318 - categorical_accuracy: 0.1838 - val_loss: 11.5312 - val_categorical_accuracy: 0.1029\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4616 - categorical_accuracy: 0.1912 - val_loss: 11.6685 - val_categorical_accuracy: 0.0882\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4291 - categorical_accuracy: 0.1923 - val_loss: 11.5087 - val_categorical_accuracy: 0.1029\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 11.4742 - categorical_accuracy: 0.1891 - val_loss: 11.6846 - val_categorical_accuracy: 0.0833\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4715 - categorical_accuracy: 0.1848 - val_loss: 11.5811 - val_categorical_accuracy: 0.1029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x226fc120898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30, \n",
    "          validation_data=val_dataset, \n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict\n",
    "\n",
    "- The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy data and a `tf.data.Dataset`.\n",
    "\n",
    "- To *evaluate* the inference-mode loss and metrics for the data provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 120us/sample - loss: 11.6201 - categorical_accuracy: 0.1150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4737 - categorical_accuracy: 0.1542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.473672898610433, 0.15416667]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add to *predict* the output of the last layer in inference for the data provided, as a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
