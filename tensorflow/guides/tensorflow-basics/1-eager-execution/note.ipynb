{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Source dump\n",
				"\n",
				"- https://www.tensorflow.org/guide/eager\n",
				"- http://web.archive.org/web/20200802155249/https://www.tensorflow.org/guide/eager\n",
				"- https://github.com/tensorflow/docs/blob/3ce5b40191bf8ff8f3663b015815940fbc5907e5/site/en/guide/eager.ipynb"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Eager execution\n",
				"\n",
				"TensorFlow's eager execution is an imperative programming environment that evaluates operation immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive `python` interpreter.\n",
				"\n",
				"Eager execution is a flexible machine learning platform for research and experimentation, providing:\n",
				"\n",
				"- _An intuitive interface_ - Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.\n",
				"- _Easier debugging_ - Call ops directly to inspect running models and test changes. Use standard Python debugging tools for immediate error reporting.\n",
				"- _Natural control flow_ - Use Python control flow instead of graph control flow, simplifying the specification of dynamic models.\n",
				"\n",
				"Eager execution supports most TensorFlow operations and GPU acceleration.\n",
				"\n",
				"> __Note:__ Some models may experience increased overhead with eager execution enabled. Performance improvements are ongoing, but please file a bug if you find a problem and share your benchmarks."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Setup and basic usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import os\n",
				"import tensorflow as tf"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"import cProfile"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"In TensorFlow 2.0, eager execution is enabled by default."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"True"
						]
					},
					"execution_count": 3,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"tf.executing_eagerly()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Now you can run TensorFlow operations and the results will return immediately:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"hello, tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
					]
				}
			],
			"source": [
				"x = [[2.]]\n",
				"m = tf.matmul(x, x)\n",
				"print('hello,', m)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Enabling eager execution changes how TensorFlow operations behave - now they immediately evaluate and return their values to Python. `tf.Tensor` objects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isn't a computational graph to build and run later in a session, it's easy to inspect results using `print()` or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients.\n",
				"\n",
				"Eager execution works nicely with NumPy. NumPy operations accept `tf.Tensor` arguments. The TensorFlow `tf.math` operations convert Python objects and NumPy arrays to `tf.Tensor` objects. The `tf.Tensor.numpy` method returns the object's value as a NumPy `ndarray`."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tf.Tensor(\n",
						"[[1 2]\n",
						" [3 4]], shape=(2, 2), dtype=int32)\n"
					]
				}
			],
			"source": [
				"a = tf.constant([[1, 2], [3, 4]])\n",
				"print(a)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tf.Tensor(\n",
						"[[2 3]\n",
						" [4 5]], shape=(2, 2), dtype=int32)\n"
					]
				}
			],
			"source": [
				"# Broadcasting support\n",
				"b = tf.add(a, 1)\n",
				"print(b)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tf.Tensor(\n",
						"[[ 2  6]\n",
						" [12 20]], shape=(2, 2), dtype=int32)\n"
					]
				}
			],
			"source": [
				"# Operator overloading is supported\n",
				"print(a * b)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[[ 2  6]\n",
						" [12 20]]\n"
					]
				}
			],
			"source": [
				"# Use NumPy values\n",
				"import numpy as np\n",
				"\n",
				"c = np.multiply(a, b)\n",
				"print(c)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[[1 2]\n",
						" [3 4]]\n"
					]
				}
			],
			"source": [
				"# Obtain numpy value from a tensor:\n",
				"print(a.numpy())"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Dynamic control flow\n",
				"\n",
				"A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to fizzbuzz:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [],
			"source": [
				"def fizzbuzz(max_num):\n",
				"    counter = tf.constant(0)\n",
				"    max_num = tf.convert_to_tensor(max_num)\n",
				"    for num in range(1, max_num.numpy()+1):\n",
				"        num = tf.constant(num)\n",
				"        if int(num % 3) == 0 and int(num % 5) == 0:\n",
				"            print('FizzBuzz')\n",
				"        elif int(num % 3) == 0:\n",
				"            print('Fizz')\n",
				"        elif int(num % 5) == 0:\n",
				"            print('Buzz')\n",
				"        else:\n",
				"            print(num.numpy())\n",
				"        counter += 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"1\n",
						"2\n",
						"Fizz\n",
						"4\n",
						"Buzz\n",
						"Fizz\n",
						"7\n",
						"8\n",
						"Fizz\n",
						"Buzz\n",
						"11\n",
						"Fizz\n",
						"13\n",
						"14\n",
						"FizzBuzz\n"
					]
				}
			],
			"source": [
				"fizzbuzz(15)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"This has conditionals that depend on tensor values and it prints these values at runtime."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Eager training\n",
				"\n",
				"### Computing gradients\n",
				"\n",
				"Automatic differentiation is useful for implementing machine learning algorithms such as backpropagration for training neural networks. During eager execution, use `tf.GradientTape` to trace operations for computing gradients later.\n",
				"\n",
				"You can use `tf.GradientTape` to train and/or compute gradients in eager. It is especially useful for complicated training loops.\n",
				"\n",
				"Since different operations can occur during each call, all forward-pass operations get recorded to a \"tape\". To compute the gradient, play the tape backwards and then discard. A particular `tf.GradientTape` can only compute one gradient; subsequent calls throw a runtime error."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
					]
				}
			],
			"source": [
				"w = tf.Variable([[1.0]])\n",
				"with tf.GradientTape() as tape:\n",
				"    loss = w * w\n",
				"\n",
				"grad = tape.gradient(loss, w)\n",
				"print(grad)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Train a model\n",
				"\n",
				"The following example creates a multi-layer model that classifies the standard MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build trainable graphs in an eager execution environment."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [],
			"source": [
				"import tensorflow.keras"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"from tensorflow import keras"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"ERROR:root:Internal Python error in the inspect module.\n",
						"Below is the traceback from this internal error.\n",
						"\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\formatters.py\", line 224, in catch_format_error\n",
						"    r = method(self, *args, **kwargs)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\formatters.py\", line 702, in __call__\n",
						"    printer.pretty(obj)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\lib\\pretty.py\", line 394, in pretty\n",
						"    return _repr_pprint(obj, self, cycle)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\lib\\pretty.py\", line 684, in _repr_pprint\n",
						"    output = repr(obj)\n",
						"  File \"<frozen importlib._bootstrap>\", line 295, in _module_repr\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
						"    module = self._load()\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
						"    module = _importlib.import_module(self.__name__)\n",
						"  File \"d:\\python\\python37\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
						"    return _bootstrap._gcd_import(name[level:], package, level)\n",
						"  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
						"  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
						"  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
						"ModuleNotFoundError: No module named 'tensorflow_core.keras'\n",
						"\n",
						"During handling of the above exception, another exception occurred:\n",
						"\n",
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
						"    stb = value._render_traceback_()\n",
						"AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
						"\n",
						"During handling of the above exception, another exception occurred:\n",
						"\n",
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
						"    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
						"    return f(*args, **kwargs)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
						"    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
						"    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
						"    filename = getsourcefile(frame) or getfile(frame)\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
						"    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 733, in getmodule\n",
						"    if ismodule(module) and hasattr(module, '__file__'):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
						"    module = self._load()\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
						"    module = _importlib.import_module(self.__name__)\n",
						"  File \"d:\\python\\python37\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
						"    return _bootstrap._gcd_import(name[level:], package, level)\n",
						"  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
						"  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
						"  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
						"ModuleNotFoundError: No module named 'tensorflow_core.keras'\n"
					]
				},
				{
					"ename": "ModuleNotFoundError",
					"evalue": "No module named 'tensorflow_core.keras'",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
					]
				}
			],
			"source": [
				"keras"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"ERROR:root:Internal Python error in the inspect module.\n",
						"Below is the traceback from this internal error.\n",
						"\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
						"    exec(code_obj, self.user_global_ns, self.user_ns)\n",
						"  File \"<ipython-input-19-3d458f16a66c>\", line 2, in <module>\n",
						"    (mnist_images, mnist_labels), _ = keras.datasets.mnist.load_data()\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
						"    module = self._load()\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
						"    module = _importlib.import_module(self.__name__)\n",
						"  File \"d:\\python\\python37\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
						"    return _bootstrap._gcd_import(name[level:], package, level)\n",
						"  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
						"  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
						"  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
						"ModuleNotFoundError: No module named 'tensorflow_core.keras'\n",
						"\n",
						"During handling of the above exception, another exception occurred:\n",
						"\n",
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
						"    stb = value._render_traceback_()\n",
						"AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
						"\n",
						"During handling of the above exception, another exception occurred:\n",
						"\n",
						"Traceback (most recent call last):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
						"    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
						"    return f(*args, **kwargs)\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
						"    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
						"    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
						"    filename = getsourcefile(frame) or getfile(frame)\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
						"    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
						"  File \"d:\\python\\python37\\lib\\inspect.py\", line 733, in getmodule\n",
						"    if ismodule(module) and hasattr(module, '__file__'):\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
						"    module = self._load()\n",
						"  File \"d:\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
						"    module = _importlib.import_module(self.__name__)\n",
						"  File \"d:\\python\\python37\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
						"    return _bootstrap._gcd_import(name[level:], package, level)\n",
						"  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
						"  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
						"  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
						"ModuleNotFoundError: No module named 'tensorflow_core.keras'\n"
					]
				},
				{
					"ename": "ModuleNotFoundError",
					"evalue": "No module named 'tensorflow_core.keras'",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
					]
				}
			],
			"source": [
				"# Fetch and format the mnist data\n",
				"(mnist_images, mnist_labels), _ = keras.datasets.mnist.load_data()\n",
				"\n",
				"dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[..., tf.newaxis]/255, tf.float32), tf.cast(mnist_labels, tf.int64)))\n",
				"dataset = dataset.shuffle(1000).batch(32)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
