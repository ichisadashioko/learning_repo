{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Build a linear model with Estimators\n",
				"\n",
				"- This tutorial uses the `tf.estimator` API in TensorFlow to solve a benchmark binary classification problem. Estimators are TensorFlow's most scalable and production-oriented model type. For more information see the [Estimator guide](https://www.tensorflow.org/guide/estimators).\n",
				"\n",
				"## Overview\n",
				"\n",
				"- Using census data which contains data a person's age, education, martial status, and occupation (the *features*), we will try to predict whether or not the person earns more than 50,000 dollars a year (the target *label*). We will train a *logistic regression* model that, given an individual's information, outputs a number between 0 and 1 - this can be interpreted as the probability that the individual has an annual income of over 50,000 dollars.\n",
				"\n",
				"- **Key Point**: As a modeler and developer, think about how the data is used and the potential benefits and harm a model's predictions can cause. A model like this could reinforce societal biases and disparities. Is each feature relevant to the problem you want to solve or will it introduce bias? For more information, read about [ML fairness](https://developers.google.com/machine-learning/fairness-overview/)."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Setup\n",
				"\n",
				"- Import TensorFlow, feature column support, and supporting modules:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"import tensorflow as tf\n",
				"import tensorflow.feature_column as fc\n",
				"\n",
				"import os\n",
				"import sys\n",
				"\n",
				"import matplotlib.pyplot as plt\n",
				"from IPython.display import clear_output"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- And let's enable [eager execution](https://www.tensorflow.org/guide/eager) to inspect this program as we run it:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"tf.enable_eager_execution()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Download the official implementation\n",
				"\n",
				"- We'll use the [wide and deep model](https://github.com/tensorflow/models/tree/master/official/wide_deep/) available in TensorFlow's [model repository](https://github.com/tensorflow/models/). Download the code, and the root directory to your Python path, and jump to the `wide_deep` directory:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Cloning into 'models'...\n",
						"remote: Enumerating objects: 3025, done.\u001b[K\n",
						"remote: Counting objects: 100% (3025/3025), done.\u001b[K\n",
						"remote: Compressing objects: 100% (2544/2544), done.\u001b[K\n",
						"remote: Total 3025 (delta 534), reused 2097 (delta 404), pack-reused 0\u001b[K\n",
						"Receiving objects: 100% (3025/3025), 370.36 MiB | 5.99 MiB/s, done.\n",
						"Resolving deltas: 100% (534/534), done.\n",
						"Checking out files: 100% (2859/2859), done.\n"
					]
				}
			],
			"source": [
				"!pip install -q requests\n",
				"!git clone --depth 1 https://github.com/tensorflow/models"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- Add the root directory of the repository to your Python path:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"models_path = os.path.join(os.getcwd(), 'models')\n",
				"sys.path.append(models_path)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- Download the dataset:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"from official.wide_deep import census_dataset\n",
				"from official.wide_deep import census_main\n",
				"\n",
				"census_dataset.download(\"/tmp/census_data/\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Command line usage\n",
				"\n",
				"- The repo includes a complete program for experimenting with this type of model.\n",
				"\n",
				"- To execute the tutorial code from the command line first add the path to tensorflow/models to your `PYTHONPATH`."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"#export PYTHONPATH=${PYTHONPATH}:\"$(pwd)/models\"\n",
				"#running from python you need to set the `os.environ` or subprocess will not see the directory\n",
				"\n",
				"if \"PYTHONPATH\" in os.environ:\n",
				"    os.environ['PYTHONPATH'] += os.pathsep + models_path\n",
				"else:\n",
				"    os.environ['PYTHONPATH'] = models_path"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- Use `--help` to see what command line options are available:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"/usr/bin/python3: Error while finding module specification for 'official.wide_deep.census_main' (ModuleNotFoundError: No module named 'official')\r\n"
					]
				}
			],
			"source": [
				"!python -m official.wide_deep.census_main --help"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- Now run the model:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Read the U.S. Census data\n",
				"\n",
				"- This example uses the [U.S Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income) from 1994 and 1995. We have provided the [census_dataset.py](https://github.com/tensorflow/models/tree/master/official/wide_deep/census_dataset.py) script to download the data and perform a little cleanup.\n",
				"\n",
				"- Since the task is *binary classification problem*, we'll construct a label column named \"label\" whose value is 1 if the income is over 50K, and 0 otherwise. For reference, see the `input_fn` in [census_main.py](https://github.com/tensorflow/models/tree/master/official/wide_deep/census_main.py)\n",
				"\n",
				"- Let's look at the data to see which columns we can use to predict the target label:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"adult.data  adult.test\r\n"
					]
				}
			],
			"source": [
				"!ls /tmp/census_data/"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [],
			"source": [
				"train_file = \"/tmp/census_data/adult.data\"\n",
				"test_file = \"/tmp/census_data/adult.test\""
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- [pandas](https://pandas.pydata.org/) provides some convenient utilities for data analysis. Here's a list of columns available in the Census Income dataset:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>age</th>\n",
							"      <th>workclass</th>\n",
							"      <th>fnlwgt</th>\n",
							"      <th>education</th>\n",
							"      <th>education_num</th>\n",
							"      <th>marital_status</th>\n",
							"      <th>occupation</th>\n",
							"      <th>relationship</th>\n",
							"      <th>race</th>\n",
							"      <th>gender</th>\n",
							"      <th>capital_gain</th>\n",
							"      <th>capital_loss</th>\n",
							"      <th>hours_per_week</th>\n",
							"      <th>native_country</th>\n",
							"      <th>income_bracket</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>39</td>\n",
							"      <td>State-gov</td>\n",
							"      <td>77516</td>\n",
							"      <td>Bachelors</td>\n",
							"      <td>13</td>\n",
							"      <td>Never-married</td>\n",
							"      <td>Adm-clerical</td>\n",
							"      <td>Not-in-family</td>\n",
							"      <td>White</td>\n",
							"      <td>Male</td>\n",
							"      <td>2174</td>\n",
							"      <td>0</td>\n",
							"      <td>40</td>\n",
							"      <td>United-States</td>\n",
							"      <td>&lt;=50K</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>50</td>\n",
							"      <td>Self-emp-not-inc</td>\n",
							"      <td>83311</td>\n",
							"      <td>Bachelors</td>\n",
							"      <td>13</td>\n",
							"      <td>Married-civ-spouse</td>\n",
							"      <td>Exec-managerial</td>\n",
							"      <td>Husband</td>\n",
							"      <td>White</td>\n",
							"      <td>Male</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>13</td>\n",
							"      <td>United-States</td>\n",
							"      <td>&lt;=50K</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>38</td>\n",
							"      <td>Private</td>\n",
							"      <td>215646</td>\n",
							"      <td>HS-grad</td>\n",
							"      <td>9</td>\n",
							"      <td>Divorced</td>\n",
							"      <td>Handlers-cleaners</td>\n",
							"      <td>Not-in-family</td>\n",
							"      <td>White</td>\n",
							"      <td>Male</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>40</td>\n",
							"      <td>United-States</td>\n",
							"      <td>&lt;=50K</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>53</td>\n",
							"      <td>Private</td>\n",
							"      <td>234721</td>\n",
							"      <td>11th</td>\n",
							"      <td>7</td>\n",
							"      <td>Married-civ-spouse</td>\n",
							"      <td>Handlers-cleaners</td>\n",
							"      <td>Husband</td>\n",
							"      <td>Black</td>\n",
							"      <td>Male</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>40</td>\n",
							"      <td>United-States</td>\n",
							"      <td>&lt;=50K</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>28</td>\n",
							"      <td>Private</td>\n",
							"      <td>338409</td>\n",
							"      <td>Bachelors</td>\n",
							"      <td>13</td>\n",
							"      <td>Married-civ-spouse</td>\n",
							"      <td>Prof-specialty</td>\n",
							"      <td>Wife</td>\n",
							"      <td>Black</td>\n",
							"      <td>Female</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>40</td>\n",
							"      <td>Cuba</td>\n",
							"      <td>&lt;=50K</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"   age         workclass  fnlwgt  education  education_num  \\\n",
							"0   39         State-gov   77516  Bachelors             13   \n",
							"1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
							"2   38           Private  215646    HS-grad              9   \n",
							"3   53           Private  234721       11th              7   \n",
							"4   28           Private  338409  Bachelors             13   \n",
							"\n",
							"       marital_status         occupation   relationship   race  gender  \\\n",
							"0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
							"1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
							"2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
							"3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
							"4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
							"\n",
							"   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
							"0          2174             0              40  United-States          <=50K  \n",
							"1             0             0              13  United-States          <=50K  \n",
							"2             0             0              40  United-States          <=50K  \n",
							"3             0             0              40  United-States          <=50K  \n",
							"4             0             0              40           Cuba          <=50K  "
						]
					},
					"execution_count": 10,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"import pandas\n",
				"\n",
				"train_df = pandas.read_csv(train_file, header=None, names=census_dataset._CSV_COLUMNS)\n",
				"test_df = pandas.read_csv(test_file, header=None, names=census_dataset._CSV_COLUMNS)\n",
				"\n",
				"train_df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- The columns are grouped into two types: *categorical* and *continuous* columns:\n",
				"\n",
				"    - A column is called *categorical* if its value can only be one of the categories in a finite set. For example, the relationship status of a person (wife, husband, unmarried, etc.) or the education level (high school, college, etc.) are categorical columns.\n",
				"    \n",
				"    - A column is called *continuous* if its value can be any numerical value in a continuous range. For example, the capital gain of a person (e.g. $14,084) is a continuous column."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Converting Data into Tensors\n",
				"\n",
				"- When building a `tf.estimator` model, the input data is specified by using and *input function* (or `input_fn`). This builder function returns a `tf.data.Dataset` of batches of `(features-dict, label)` pairs. It is not called until it is passed to `tf.estimator.Estimator` methods such as `train` and evaluate`.\n",
				"\n",
				"- The input builder function returns the following pair:\n",
				"\n",
				"    1. `features`: A dict from feature names to `Tensors` or `SparseTensors` containing batches of features.\n",
				"    2. `labels`: A `Tensor` containing batches of labels.\n",
				"    \n",
				"- The keys of the `features` are used to configure the model's input layer.\n",
				"\n",
				"- **Note**: The input function is called while constructing the TensorFlow graph, *not* while running the graph. It is returning a representation of the input data as a sequence of TensorFlow graph operations.\n",
				"\n",
				"- For small problems like this, it's easy to make a `tf.data.Dataset` by slicing the `pandas.DataFrame`:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {},
			"outputs": [],
			"source": [
				"def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
				"    label = df[label_key]\n",
				"    ds = tf.data.Dataset.from_tensor_slices((dict(df), label))\n",
				"    \n",
				"    if shuffle:\n",
				"        ds = ds.shuffle(10000)\n",
				"        \n",
				"    ds = ds.batch(batch_size).repeat(num_epochs)\n",
				"    \n",
				"    return ds"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- Since we have eager execution enabled, it's easy to inspect the resulting dataset:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
						"\n",
						"A batch of Ages : tf.Tensor([20 37 49 23 33 47 32 44 41 44], shape=(10,), dtype=int32)\n",
						"\n",
						"A batch of Labels: tf.Tensor(\n",
						"[b'<=50K' b'>50K' b'>50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K'\n",
						" b'<=50K' b'<=50K'], shape=(10,), dtype=string)\n"
					]
				}
			],
			"source": [
				"ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
				"\n",
				"for feature_batch, label_batch in ds.take(1):\n",
				"    print('Some feature keys:', list(feature_batch.keys())[:5])\n",
				"    print()\n",
				"    print('A batch of Ages :', feature_batch['age'])\n",
				"    print()\n",
				"    print('A batch of Labels:', label_batch)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- But this approach has severly-limited scalability. Larger datasets should be streamed from disk. The `census_dataset.input_fn` provides an example of how to do this using `tf.decode_csv` and `tf.data.TextLineDataset`:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
						"  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
						"  assert tf.gfile.Exists(data_file), (\n",
						"      '%s not found. Please make sure you have run census_dataset.py and '\n",
						"      'set the --data_dir argument to the correct path.' % data_file)\n",
						"\n",
						"  def parse_csv(value):\n",
						"    tf.logging.info('Parsing {}'.format(data_file))\n",
						"    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
						"    features = dict(zip(_CSV_COLUMNS, columns))\n",
						"    labels = features.pop('income_bracket')\n",
						"    classes = tf.equal(labels, '>50K')  # binary classification\n",
						"    return features, classes\n",
						"\n",
						"  # Extract lines from input files using the Dataset API.\n",
						"  dataset = tf.data.TextLineDataset(data_file)\n",
						"\n",
						"  if shuffle:\n",
						"    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
						"\n",
						"  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
						"\n",
						"  # We call repeat after shuffling, rather than before, to prevent separate\n",
						"  # epochs from blending together.\n",
						"  dataset = dataset.repeat(num_epochs)\n",
						"  dataset = dataset.batch(batch_size)\n",
						"  return dataset\n",
						"\n"
					]
				}
			],
			"source": [
				"import inspect\n",
				"print(inspect.getsource(census_dataset.input_fn))"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
